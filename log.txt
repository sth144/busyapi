Sean Hinds
30 March, 2018

Development Log: Scaling BusyAPI to 1M Users per Minute

/* Problem Analysis, Initial Thoughts, Environment Setup*/
I examined the repository, and read the README and all of the code files. I constructed a mental diagram of how the application works. It is a standard Express.js application which uses a fairly simple routing structure to handle different urls. The critical endpoint is './routes/api/usages', which contains a POST HTTP request handler for the url appendage: ‘/api/usages’. The callback to this route handler pushes the POST request body to an array in memory for storage. It then sets usageId as the length of the usage array. Array.length in JavaScript is an O(1) time-complexity operation, so there is should be no performance boost to changing this to ‘usageId++;’. 
I opened a Git Bash shell, Chrome browser window for testing, and a Sublime project folder with my cloned fork of busyapi. I ran npm install and npm start. 

/* Initial Test Development and Code Implementation */
First I needed to develop a way to demonstrate the problem, and then a way to test the use case so that I could assess my code changes. I wrote a crude bash script which and takes a command line argument specifying the number of requests to make, and then calls the curl command from README.md in a for-loop.
A quick test for 1-10,000 requests showed O(n) time complexity, as expected. However, the number of requests per second was only about 100R/s. It quickly became clear to me that I was seeing was the limit of the amount of requests my local machine could generate--not at all a metric of server capacity.
I tested various load testing software packages, including artillery and wrk. I encountered a plateau of about 50R/s with both artillery and wrk (again testing in the range of 1-10,000): 

	RPS     latency	system runtime (ms)
1	2.04	7.6	152
10	7.14	1.9	166
100	39.84	1.5	106
1000	48.83	1.4	200
10000	49.86	1.2	60

This plateau was probably an artefact of my local environment. I Decided to implement some code and revisit testing shortly (see below). 
Node.js is single threaded but it should be asynchronous by default. That means the callback in the post request handler should not block other requests. To verify this, I used the setTimeout() function to pause during the callback, and observed that later requests were still processed while a given request was paused in the callback. My setTimeout() test also supported my assumption above that my testing bottleneck was due to my local machine. This is because without pausing in the callback, requests appear to be processed synchronously, so the arrival of HTTP requests is rate-limiting. 
I introduced clustering using the npm cluster module and the fork() function. This should allow the node server to distribute work over the multiple cores on my CPU, which could improve performance.
Further research indicated that each worker process in a clustered node program has its own memory, so I needed to implement shared memory between workers. Researched caching packages like redis, node-cache and memcached; decided to implement memcached. In the future, this cache could be dumped into a database like mongoDB for persistent storage.

/* Further Test Development and Code Implementation */
I revisited test development, testing the server with Apache Benchmark software. Much to my delight, this package did not encounter the 50R/s plateau I saw with artillery and wrk. With Apache benchmark, I could apparently get data for up to 10,000 users. For the purposes of this quick exercise, I decided to assume that a R/s of ~16,000 would server as a proxy for 1 million users per minute. This is because each user is only transferring a small JSON object, so a request should only occupy a server port transiently.
I re-collected data for 1-10,000 users, toggling cluster + caching, and got some interesting results:

unclustered + uncached
Number of Users	Runtime (ms)	Requests per Second
1		16		63.98
10		7		1424.7
100		78		1279.85
1000		1687		592.94
10000		17503		612.93
		
clustered + cached	
Number of Users	Runtime (ms)	Requests per Second
1		16		63.88
10		31		320.24
100		31		3202.56
1000		1768		565.77
10000		20582		485.87

Clustering and caching apparently decreased performance almost 5-fold for low call volumes. This is probably because the computational overhead of clustering negates the benefits of parallelism. I appeared to achieve peak performance on my local machine at 100 users. Assuming this result is genuine, at 100 users, clustering and caching appears to increase performance nearly three-fold, to ~3200R/s. This is still far from the target of ~16,000R/s. The performance increase from clustering would likely be greater if there were a computationally intensive endpoint. I think I only see a small benefit at 100 users because there is little computation involved in processing each request. Poor performance for levels of users 1000 and above is likely due to limitations of my local machine. 
I also tried commenting out console logs, and morgan logging, which did not improve performance. I attempted to use the npm redis module instead of memcached, but found it to be buggy, and reverted to memcached due to my time constraint. 

/* Software/Hardware Architecture Suggestions */
I believe my implementation of caching and clustering should improve performance. A better testing environment is necessary to confirm this. Perhaps distributed load testing would allow for testing of higher numbers of users. Regardless, as this application needs to service a high volume of clients, a parallel software architecture (clustering) would be a good route to pursue.
Assuming clustered execution in the software, this app should be run on a server with a high number of hyperthreaded CPU cores for parallel processing, as well as a high volume of memory for caching. Horizontal scaling could also be implemented, with multiple machines receiving requests. A server machine with a high volume of storage should be used as a database.

/* Next Steps */
I decided to try deploying the application using Google Cloud. I found this decreased performance. In the future I would like to troubleshoot this, but the time constraint of this exercise does not allow for this.

